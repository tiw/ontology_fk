#!/usr/bin/env python3
"""
æ€§èƒ½ä¼˜åŒ–æ¼”ç¤ºè„šæœ¬

å±•ç¤ºæ–°å®ç°çš„æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç¼“å­˜ã€ç´¢å¼•ã€æ‰¹é‡å¤„ç†ç­‰ã€‚
"""

import sys
import os
import time

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    from ontology_framework.performance import (
        CacheManager, LRUCache, IndexManager, IndexDefinition,
        PerformanceAdvisor, BatchProcessor, BatchConfig,
        cached, performance_monitored
    )
    from ontology_framework.optimized_core import OptimizedOntology
    from ontology_framework.core import ObjectType, ObjectInstance, PropertyType
    print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)


def demonstrate_caching():
    """æ¼”ç¤ºç¼“å­˜åŠŸèƒ½"""
    print("\nğŸ” ç¼“å­˜åŠŸèƒ½æ¼”ç¤º")
    print("=" * 40)

    # 1. åŸºæœ¬ç¼“å­˜æ“ä½œ
    cache = LRUCache(max_size=5, ttl_seconds=2)
    print("åˆ›å»ºLRUç¼“å­˜: æœ€å¤§å®¹é‡=5, TTL=2ç§’")

    # æ·»åŠ æ•°æ®
    cache.put("user:1", "Alice")
    cache.put("user:2", "Bob")
    cache.put("user:3", "Charlie")
    print("æ·»åŠ 3ä¸ªç”¨æˆ·æ•°æ®")

    # è·å–æ•°æ®
    print(f"è·å–ç”¨æˆ·1: {cache.get('user:1')}")
    print(f"è·å–ç”¨æˆ·2: {cache.get('user:2')}")

    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = cache.get_stats()
    print(f"ç¼“å­˜ç»Ÿè®¡: å¤§å°={stats['size']}, å‘½ä¸­ç‡={stats['hit_rate']:.2%}")

    # 2. ç¼“å­˜è£…é¥°å™¨
    print("\nç¼“å­˜è£…é¥°å™¨æ¼”ç¤º:")
    call_count = 0

    @cached(cache_name="expensive_calc", ttl_seconds=1)
    def expensive_calculation(x, y):
        nonlocal call_count
        call_count += 1
        time.sleep(0.1)  # æ¨¡æ‹Ÿè€—æ—¶è®¡ç®—
        return x * y

    # ç¬¬ä¸€æ¬¡è°ƒç”¨
    start = time.time()
    result1 = expensive_calculation(10, 20)
    time1 = time.time() - start
    print(f"ç¬¬ä¸€æ¬¡è°ƒç”¨: {result1}, è€—æ—¶={time1:.3f}s, è°ƒç”¨æ¬¡æ•°={call_count}")

    # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆåº”è¯¥ä»ç¼“å­˜è·å–ï¼‰
    start = time.time()
    result2 = expensive_calculation(10, 20)
    time2 = time.time() - start
    print(f"ç¬¬äºŒæ¬¡è°ƒç”¨: {result2}, è€—æ—¶={time2:.3f}s, è°ƒç”¨æ¬¡æ•°={call_count}")

    print(f"ç¼“å­˜åŠ é€Ÿæ¯”: {time1/time2:.1f}x")


def demonstrate_indexing():
    """æ¼”ç¤ºç´¢å¼•åŠŸèƒ½"""
    print("\nğŸ” ç´¢å¼•åŠŸèƒ½æ¼”ç¤º")
    print("=" * 40)

    # åˆ›å»ºç´¢å¼•ç®¡ç†å™¨
    index_manager = IndexManager()

    # åˆ›å»ºç”¨æˆ·åç´¢å¼•
    name_index_def = IndexDefinition(
        name="user_name_index",
        property_name="name",
        index_type="hash",
        unique=False
    )
    name_index = index_manager.create_index(name_index_def)
    print("åˆ›å»ºç”¨æˆ·åç´¢å¼•")

    # æ·»åŠ ç´¢å¼•æ•°æ®
    users = [
        ("Alice", "user1"),
        ("Bob", "user2"),
        ("Alice", "user3"),  # é‡åç”¨æˆ·
        ("Charlie", "user4"),
        ("Bob", "user5")
    ]

    for name, user_id in users:
        name_index.add(name, user_id)

    print(f"æ·»åŠ äº†{len(users)}ä¸ªç”¨æˆ·åˆ°ç´¢å¼•")

    # æŸ¥è¯¢æ¼”ç¤º
    alice_users = name_index.find("Alice")
    bob_users = name_index.find("Bob")
    unknown_users = name_index.find("Unknown")

    print(f"æŸ¥è¯¢ 'Alice': {alice_users}")
    print(f"æŸ¥è¯¢ 'Bob': {bob_users}")
    print(f"æŸ¥è¯¢ 'Unknown': {unknown_users}")

    # æ˜¾ç¤ºç´¢å¼•ç»Ÿè®¡
    stats = name_index.get_stats()
    print(f"ç´¢å¼•ç»Ÿè®¡: æ€»å€¼={stats['total_values']}, æ€»å¯¹è±¡={stats['total_objects']}")


def demonstrate_batch_processing():
    """æ¼”ç¤ºæ‰¹é‡å¤„ç†åŠŸèƒ½"""
    print("\nğŸ” æ‰¹é‡å¤„ç†åŠŸèƒ½æ¼”ç¤º")
    print("=" * 40)

    # åˆ›å»ºä¼˜åŒ–çš„æœ¬ä½“
    ontology = OptimizedOntology(enable_monitoring=True)

    # å®šä¹‰å‘˜å·¥å¯¹è±¡ç±»å‹
    employee_type = ObjectType("employee", "Employee", "employee_id")
    employee_type.add_property("employee_id", PropertyType.STRING)
    employee_type.add_property("name", PropertyType.STRING)
    employee_type.add_property("department", PropertyType.STRING)
    employee_type.add_property("salary", PropertyType.INTEGER)
    ontology.register_object_type(employee_type)

    print("æ³¨å†Œå‘˜å·¥å¯¹è±¡ç±»å‹")

    # æ‰¹é‡åˆ›å»ºå‘˜å·¥æ•°æ®
    departments = ["Engineering", "Sales", "Marketing", "HR"]
    employees = []

    for i in range(50):
        dept = departments[i % len(departments)]
        employee = ObjectInstance(
            object_type_api_name="employee",
            primary_key_value=f"emp_{i:03d}",
            property_values={
                "employee_id": f"emp_{i:03d}",
                "name": f"Employee {i}",
                "department": dept,
                "salary": 50000 + (i * 500)
            }
        )
        employees.append(employee)

    print(f"åˆ›å»ºäº†{len(employees)}ä¸ªå‘˜å·¥å¯¹è±¡")

    # æ‰¹é‡æ·»åŠ 
    batch_config = BatchConfig(batch_size=20)
    processor = BatchProcessor(batch_config)

    start_time = time.time()
    result = processor.batch_add_objects(ontology, employees)
    batch_time = time.time() - start_time

    print(f"æ‰¹é‡æ·»åŠ ç»“æœ:")
    print(f"  - æ€»æ•°: {result['total_objects']}")
    print(f"  - æˆåŠŸ: {result['success_count']}")
    print(f"  - å¤±è´¥: {result['error_count']}")
    print(f"  - è€—æ—¶: {batch_time:.3f}s")
    print(f"  - ååé‡: {result['throughput']:.1f} objects/sec")

    # éªŒè¯æ•°æ®
    stored_employees = ontology.get_objects_of_type("employee")
    print(f"å­˜å‚¨çš„å‘˜å·¥æ•°é‡: {len(stored_employees.all())}")


def demonstrate_performance_monitoring():
    """æ¼”ç¤ºæ€§èƒ½ç›‘æ§åŠŸèƒ½"""
    print("\nğŸ” æ€§èƒ½ç›‘æ§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 40)

    from ontology_framework.performance import get_performance_monitor

    monitor = get_performance_monitor()

    # æ¨¡æ‹Ÿä¸€äº›æ“ä½œ
    operations = [
        ("database_query", 0.05, True),
        ("database_query", 0.08, True),
        ("database_query", 0.12, True),  # æ…¢æŸ¥è¯¢
        ("api_call", 0.02, True),
        ("api_call", 0.03, True),
        ("file_operation", 0.15, False),  # å¤±è´¥æ“ä½œ
        ("calculation", 0.001, True),
        ("calculation", 0.002, True),
    ]

    for op_name, exec_time, success in operations:
        monitor.record_operation(op_name, exec_time, success)

    print("è®°å½•äº†8ä¸ªæ“ä½œçš„æ€§èƒ½æ•°æ®")

    # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
    all_metrics = monitor.get_all_metrics()
    for op_name, metrics in all_metrics.items():
        print(f"\n{op_name}:")
        print(f"  - æ“ä½œæ¬¡æ•°: {metrics.operation_count}")
        print(f"  - å¹³å‡è€—æ—¶: {metrics.avg_time:.3f}s")
        print(f"  - æœ€å°è€—æ—¶: {metrics.min_time:.3f}s")
        print(f"  - æœ€å¤§è€—æ—¶: {metrics.max_time:.3f}s")
        print(f"  - é”™è¯¯ç‡: {metrics.error_rate:.2%}")


def demonstrate_performance_advisor():
    """æ¼”ç¤ºæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    print("\nğŸ” æ€§èƒ½ä¼˜åŒ–å»ºè®®æ¼”ç¤º")
    print("=" * 40)

    advisor = PerformanceAdvisor()

    # ç”Ÿæˆä¸€äº›æ€§èƒ½é—®é¢˜
    monitor = advisor.performance_monitor

    # æ¨¡æ‹Ÿæ…¢æ“ä½œ
    for i in range(10):
        monitor.record_operation("slow_api_call", 0.2 + (i * 0.01), True)

    # æ¨¡æ‹Ÿé«˜é”™è¯¯ç‡æ“ä½œ
    for i in range(20):
        monitor.record_operation("unstable_operation", 0.05, i < 15)  # 15ä¸ªå¤±è´¥ï¼Œ5ä¸ªæˆåŠŸ

    # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
    report = advisor.generate_optimization_report()
    print("æ€§èƒ½ä¼˜åŒ–å»ºè®®æŠ¥å‘Š:")
    print(report)


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ Ontology Framework æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)

    try:
        demonstrate_caching()
        demonstrate_indexing()
        demonstrate_batch_processing()
        demonstrate_performance_monitoring()
        demonstrate_performance_advisor()

        print("\nâœ… æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“Š æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½æ€»ç»“:")
        print("  - âœ… LRUç¼“å­˜ç³»ç»Ÿ")
        print("  - âœ… ç¼“å­˜è£…é¥°å™¨")
        print("  - âœ… å±æ€§ç´¢å¼•ç®¡ç†")
        print("  - âœ… æ‰¹é‡æ•°æ®å¤„ç†")
        print("  - âœ… æ€§èƒ½ç›‘æ§")
        print("  - âœ… æ™ºèƒ½ä¼˜åŒ–å»ºè®®")

    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()