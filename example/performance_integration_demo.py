#!/usr/bin/env python3
"""
æ€§èƒ½ä¼˜åŒ–é›†æˆæ¼”ç¤º

å±•ç¤ºå¦‚ä½•å°†æ€§èƒ½ä¼˜åŒ–åŠŸèƒ½é›†æˆåˆ°å®é™…çš„ Ontology Framework åº”ç”¨ä¸­ã€‚
"""

import sys
import os
import time

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from ontology_framework.optimized_core import OptimizedOntology
from ontology_framework.performance import (
    PerformanceOptimizerAdapter, BatchProcessor, BatchConfig,
    MemoryOptimizer, get_performance_monitor
)
from ontology_framework.core import ObjectType, ObjectInstance, PropertyType


def demonstrate_optimized_employee_management():
    """æ¼”ç¤ºä¼˜åŒ–çš„å‘˜å·¥ç®¡ç†ç³»ç»Ÿ"""
    print("\nğŸ¢ ä¼˜åŒ–çš„å‘˜å·¥ç®¡ç†ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)

    # åˆ›å»ºä¼˜åŒ–çš„æœ¬ä½“
    ontology = OptimizedOntology(enable_monitoring=True, enable_cache=True)
    print("âœ… åˆ›å»ºä¼˜åŒ–çš„æœ¬ä½“æˆåŠŸ")

    # å®šä¹‰å‘˜å·¥å¯¹è±¡ç±»å‹
    employee_type = ObjectType("employee", "Employee", "employee_id")
    employee_type.add_property("employee_id", PropertyType.STRING, description="å‘˜å·¥ID")
    employee_type.add_property("name", PropertyType.STRING, description="å§“å")
    employee_type.add_property("department", PropertyType.STRING, description="éƒ¨é—¨")
    employee_type.add_property("position", PropertyType.STRING, description="èŒä½")
    employee_type.add_property("salary", PropertyType.INTEGER, description="è–ªèµ„")
    employee_type.add_property("hire_date", PropertyType.DATE, description="å…¥èŒæ—¥æœŸ")
    ontology.register_object_type(employee_type)

    # å®šä¹‰éƒ¨é—¨å¯¹è±¡ç±»å‹
    department_type = ObjectType("department", "Department", "dept_id")
    department_type.add_property("dept_id", PropertyType.STRING, description="éƒ¨é—¨ID")
    department_type.add_property("name", PropertyType.STRING, description="éƒ¨é—¨åç§°")
    department_type.add_property("manager", PropertyType.STRING, description="éƒ¨é—¨ç»ç†")
    ontology.register_object_type(department_type)

    print("âœ… æ³¨å†Œå¯¹è±¡ç±»å‹æˆåŠŸ")

    # åˆ›å»ºæ€§èƒ½ä¼˜åŒ–é€‚é…å™¨å¹¶å®‰è£…ä¼˜åŒ–
    adapter = PerformanceOptimizerAdapter(ontology)
    adapter.install_optimizations()
    print("âœ… å®‰è£…æ€§èƒ½ä¼˜åŒ–æˆåŠŸ")

    # æ‰¹é‡åˆ›å»ºéƒ¨é—¨æ•°æ®
    departments = [
        ("dept001", "Engineering", "Alice Johnson"),
        ("dept002", "Sales", "Bob Smith"),
        ("dept003", "Marketing", "Carol Davis"),
        ("dept004", "HR", "David Wilson"),
    ]

    department_objects = []
    for dept_id, name, manager in departments:
        dept = ObjectInstance(
            object_type_api_name="department",
            primary_key_value=dept_id,
            property_values={
                "dept_id": dept_id,
                "name": name,
                "manager": manager
            }
        )
        department_objects.append(dept)

    # æ‰¹é‡æ·»åŠ éƒ¨é—¨
    batch_processor = BatchProcessor(BatchConfig(batch_size=10))
    dept_result = batch_processor.batch_add_objects(ontology, department_objects)
    print(f"âœ… æ‰¹é‡æ·»åŠ éƒ¨é—¨æˆåŠŸ: {dept_result['success_count']}/{dept_result['total_objects']}")

    # æ‰¹é‡åˆ›å»ºå‘˜å·¥æ•°æ®
    employees = []
    positions = ["Engineer", "Senior Engineer", "Manager", "Director", "Analyst"]
    departments_list = ["Engineering", "Sales", "Marketing", "HR"]

    for i in range(200):
        dept = departments_list[i % len(departments_list)]
        position = positions[i % len(positions)]

        employee = ObjectInstance(
            object_type_api_name="employee",
            primary_key_value=f"emp_{i:04d}",
            property_values={
                "employee_id": f"emp_{i:04d}",
                "name": f"Employee {i}",
                "department": dept,
                "position": position,
                "salary": 50000 + (i * 100) + (len(position) * 5000),
                "hire_date": f"2020-{(i % 12) + 1:02d}-15"
            }
        )
        employees.append(employee)

    # æ‰¹é‡æ·»åŠ å‘˜å·¥
    start_time = time.time()
    emp_result = batch_processor.batch_add_objects(ontology, employees)
    batch_time = time.time() - start_time

    print(f"âœ… æ‰¹é‡æ·»åŠ å‘˜å·¥æˆåŠŸ:")
    print(f"   - æ€»æ•°: {emp_result['total_objects']}")
    print(f"   - æˆåŠŸ: {emp_result['success_count']}")
    print(f"   - è€—æ—¶: {batch_time:.3f}s")
    print(f"   - ååé‡: {emp_result['throughput']:.1f} employees/sec")

    return ontology, adapter


def demonstrate_query_performance(ontology, adapter):
    """æ¼”ç¤ºæŸ¥è¯¢æ€§èƒ½"""
    print("\nâš¡ æŸ¥è¯¢æ€§èƒ½æ¼”ç¤º")
    print("=" * 40)

    # æµ‹è¯•éƒ¨é—¨æŸ¥è¯¢
    departments = ["Engineering", "Sales", "Marketing", "HR"]

    for dept in departments:
        start_time = time.time()
        dept_employees = ontology.get_objects_of_type("employee")
        filtered = dept_employees.filter("department", dept)
        query_time = time.time() - start_time

        print(f"æŸ¥è¯¢ {dept} éƒ¨é—¨å‘˜å·¥:")
        print(f"   - ç»“æœæ•°é‡: {len(filtered.all())}")
        print(f"   - æŸ¥è¯¢æ—¶é—´: {query_time:.4f}s")
        print(f"   - å¹³å‡æ¯ä¸ªå‘˜å·¥: {query_time/max(1, len(filtered.all()))*1000:.2f}ms")

    # æ‰¹é‡æŸ¥è¯¢æµ‹è¯•
    print(f"\næ‰¹é‡æŸ¥è¯¢æµ‹è¯•:")
    queries = [
        {"department": "Engineering"},
        {"position": "Engineer"},
        {"salary": 60000},  # è¿™å¯èƒ½ä¸ä¼šåŒ¹é…ä»»ä½•ç»“æœ
    ]

    start_time = time.time()
    batch_results = batch_processor.batch_query(ontology, "employee", queries)
    batch_query_time = time.time() - start_time

    print(f"æ‰¹é‡ {len(queries)} ä¸ªæŸ¥è¯¢è€—æ—¶: {batch_query_time:.4f}s")
    print(f"æ€»ç»“æœæ•°é‡: {len(batch_results)}")


def demonstrate_memory_optimization(ontology):
    """æ¼”ç¤ºå†…å­˜ä¼˜åŒ–"""
    print("\nğŸ’¾ å†…å­˜ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 40)

    # åˆ†æå†…å­˜ä½¿ç”¨
    memory_optimizer = MemoryOptimizer(ontology)
    memory_stats = memory_optimizer.analyze_memory_usage()

    print("å†…å­˜ä½¿ç”¨åˆ†æ:")
    if "summary" in memory_stats:
        summary = memory_stats["summary"]
        print(f"   - æ€»å¯¹è±¡æ•°: {summary['total_objects']}")
        print(f"   - æ€»å†…å­˜ä½¿ç”¨: {summary['total_memory'] / 1024:.1f} KB")
        print(f"   - å¹³å‡æ¯ä¸ªå¯¹è±¡: {summary['avg_memory_per_object']} bytes")

    # è·å–ä¼˜åŒ–å»ºè®®
    suggestions = memory_optimizer.suggest_memory_optimizations()
    if suggestions:
        print("å†…å­˜ä¼˜åŒ–å»ºè®®:")
        for suggestion in suggestions:
            print(f"   - {suggestion}")
    else:
        print("âœ… å†…å­˜ä½¿ç”¨è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–å»ºè®®")

    # æ‰§è¡Œå†…å­˜ä¼˜åŒ–
    optimizations = memory_optimizer.optimize_memory_usage()
    if optimizations:
        print("å·²æ‰§è¡Œçš„å†…å­˜ä¼˜åŒ–:")
        for opt in optimizations:
            print(f"   - {opt}")


def demonstrate_performance_monitoring(ontology):
    """æ¼”ç¤ºæ€§èƒ½ç›‘æ§"""
    print("\nğŸ“Š æ€§èƒ½ç›‘æ§æ¼”ç¤º")
    print("=" * 40)

    # æ‰§è¡Œä¸€äº›æ“ä½œæ¥ç”Ÿæˆæ€§èƒ½æ•°æ®
    monitor = get_performance_monitor()

    # æ¨¡æ‹Ÿå„ç§æ“ä½œ
    for i in range(10):
        # è·å–å¯¹è±¡æ“ä½œ
        start = time.time()
        employees = ontology.get_objects_of_type("employee")
        if employees.all():
            first_employee = employees.all()[0]
            first_employee.get("name")
        monitor.record_operation("get_object", time.time() - start, True)

        # è¿‡æ»¤æ“ä½œ
        start = time.time()
        filtered = employees.filter("department", "Engineering")
        monitor.record_operation("filter_query", time.time() - start, True)

    # æ¨¡æ‹Ÿä¸€äº›æ…¢æ“ä½œ
    for i in range(3):
        start = time.time()
        time.sleep(0.01)  # æ¨¡æ‹Ÿ10msçš„å¤„ç†æ—¶é—´
        monitor.record_operation("complex_calculation", time.time() - start, True)

    # è·å–æ€§èƒ½ç»Ÿè®¡
    stats = ontology.get_performance_stats()
    print("æ€§èƒ½ç»Ÿè®¡:")

    if "operation_stats" in stats:
        op_stats = stats["operation_stats"]
        print(f"   - å¯¹è±¡åˆ›å»º: {op_stats.get('objects_created', 0)}")
        print(f"   - å¯¹è±¡è·å–: {op_stats.get('objects_retrieved', 0)}")
        print(f"   - æŸ¥è¯¢æ‰§è¡Œ: {op_stats.get('queries_executed', 0)}")

    # æ˜¾ç¤ºç›‘æ§æŒ‡æ ‡
    all_metrics = monitor.get_all_metrics()
    print("\næ“ä½œæ€§èƒ½æŒ‡æ ‡:")
    for op_name, metrics in all_metrics.items():
        if metrics.operation_count > 0:
            print(f"   - {op_name}:")
            print(f"     * æ‰§è¡Œæ¬¡æ•°: {metrics.operation_count}")
            print(f"     * å¹³å‡è€—æ—¶: {metrics.avg_time*1000:.2f}ms")
            print(f"     * æœ€å¤§è€—æ—¶: {metrics.max_time*1000:.2f}ms")
            if metrics.error_count > 0:
                print(f"     * é”™è¯¯ç‡: {metrics.error_rate:.1%}")


def demonstrate_optimization_recommendations(adapter):
    """æ¼”ç¤ºä¼˜åŒ–å»ºè®®"""
    print("\nğŸ”§ ä¼˜åŒ–å»ºè®®æ¼”ç¤º")
    print("=" * 40)

    # è·å–ä¼˜åŒ–å»ºè®®
    recommendations = adapter.get_optimization_recommendations()

    if recommendations:
        print("å½“å‰ç³»ç»Ÿä¼˜åŒ–å»ºè®®:")
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. {rec}")
    else:
        print("âœ… ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®")

    # åº”ç”¨è‡ªåŠ¨ä¼˜åŒ–
    print("\nåº”ç”¨è‡ªåŠ¨ä¼˜åŒ–...")
    adapter.apply_auto_optimizations()
    print("âœ… è‡ªåŠ¨ä¼˜åŒ–åº”ç”¨å®Œæˆ")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ Ontology Framework æ€§èƒ½ä¼˜åŒ–é›†æˆæ¼”ç¤º")
    print("=" * 60)

    try:
        # 1. åˆ›å»ºä¼˜åŒ–çš„å‘˜å·¥ç®¡ç†ç³»ç»Ÿ
        ontology, adapter = demonstrate_optimized_employee_management()

        # 2. æ¼”ç¤ºæŸ¥è¯¢æ€§èƒ½
        demonstrate_query_performance(ontology, adapter)

        # 3. æ¼”ç¤ºå†…å­˜ä¼˜åŒ–
        demonstrate_memory_optimization(ontology)

        # 4. æ¼”ç¤ºæ€§èƒ½ç›‘æ§
        demonstrate_performance_monitoring(ontology)

        # 5. æ¼”ç¤ºä¼˜åŒ–å»ºè®®
        demonstrate_optimization_recommendations(adapter)

        print("\nğŸ‰ æ€§èƒ½ä¼˜åŒ–é›†æˆæ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“ˆ é›†æˆæ•ˆæœæ€»ç»“:")
        print("  - âœ… ä¼˜åŒ–çš„æœ¬ä½“ç®¡ç†")
        print("  - âœ… è‡ªåŠ¨ç´¢å¼•åˆ›å»º")
        print("  - âœ… é«˜æ•ˆæ‰¹é‡å¤„ç†")
        print("  - âœ… æ™ºèƒ½ç¼“å­˜ç®¡ç†")
        print("  - âœ… å®æ—¶æ€§èƒ½ç›‘æ§")
        print("  - âœ… å†…å­˜ä½¿ç”¨ä¼˜åŒ–")
        print("  - âœ… è‡ªåŠ¨ä¼˜åŒ–å»ºè®®")

        # è·å–æœ€ç»ˆæ€§èƒ½æŠ¥å‘Š
        final_stats = ontology.get_performance_stats()
        if "cache_stats" in final_stats:
            cache_stats = final_stats["cache_stats"]
            print(f"\nğŸ“Š æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡:")
            print(f"   - ç¼“å­˜ç»Ÿè®¡: {len(cache_stats)} ä¸ªç¼“å­˜")
            print(f"   - æ€»å¯¹è±¡æ•°: {sum(len(objs) for objs in ontology._object_store.values())}")

    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()