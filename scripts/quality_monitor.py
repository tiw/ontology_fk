#!/usr/bin/env python3
"""
è´¨é‡ç›‘æ§è„šæœ¬

å®šæœŸç”Ÿæˆè´¨é‡æŠ¥å‘Šï¼Œç›‘æ§é¡¹ç›®è´¨é‡æŒ‡æ ‡å˜åŒ–è¶‹åŠ¿ã€‚
åŒ…å«ä»£ç è´¨é‡ã€æµ‹è¯•è¦†ç›–ç‡ã€æ€§èƒ½æŒ‡æ ‡ç­‰å¤šä¸ªç»´åº¦çš„ç›‘æ§ã€‚
"""

import json
import subprocess
import sqlite3
import argparse
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Any
import sys
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class QualityMetricsCollector:
    """è´¨é‡æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root).resolve()
        self.db_path = self.project_root / "quality_metrics.db"
        self.init_database()

    def init_database(self) -> None:
        """åˆå§‹åŒ–è´¨é‡æŒ‡æ ‡æ•°æ®åº“"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS quality_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                metric_category TEXT NOT NULL,
                metric_name TEXT NOT NULL,
                metric_value REAL NOT NULL,
                metric_metadata TEXT,
                git_commit TEXT,
                git_branch TEXT
            )
        ''')

        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_timestamp
            ON quality_metrics(timestamp)
        ''')

        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_category_name
            ON quality_metrics(metric_category, metric_name)
        ''')

        conn.commit()
        conn.close()

    def run_command(self, cmd: List[str], cwd: str = None) -> Tuple[int, str, str]:
        """æ‰§è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            work_dir = cwd or str(self.project_root)
            result = subprocess.run(
                cmd,
                cwd=work_dir,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            return result.returncode, result.stdout, result.stderr
        except subprocess.TimeoutExpired:
            logger.error(f"å‘½ä»¤æ‰§è¡Œè¶…æ—¶: {' '.join(cmd)}")
            return -1, "", "Command timeout"
        except Exception as e:
            logger.error(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            return -1, "", str(e)

    def get_git_info(self) -> Tuple[str, str]:
        """è·å–å½“å‰Gitä¿¡æ¯"""
        try:
            # è·å–å½“å‰æäº¤å“ˆå¸Œ
            returncode, commit_hash, _ = self.run_command([
                "git", "rev-parse", "HEAD"
            ])
            if returncode != 0:
                commit_hash = "unknown"

            # è·å–å½“å‰åˆ†æ”¯å
            returncode, branch_name, _ = self.run_command([
                "git", "rev-parse", "--abbrev-ref", "HEAD"
            ])
            if returncode != 0:
                branch_name = "unknown"

            return commit_hash.strip(), branch_name.strip()
        except Exception:
            return "unknown", "unknown"

    def record_metric(
        self,
        category: str,
        name: str,
        value: float,
        metadata: Dict[str, Any] = None,
        git_commit: str = None,
        git_branch: str = None
    ) -> None:
        """è®°å½•è´¨é‡æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        if git_commit is None or git_branch is None:
            git_commit, git_branch = self.get_git_info()

        cursor.execute('''
            INSERT INTO quality_metrics
            (timestamp, metric_category, metric_name, metric_value,
             metric_metadata, git_commit, git_branch)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        ''', (
            datetime.now().isoformat(),
            category,
            name,
            float(value),
            json.dumps(metadata or {}),
            git_commit,
            git_branch
        ))

        conn.commit()
        conn.close()
        logger.info(f"è®°å½•æŒ‡æ ‡: {category}/{name} = {value}")

    def collect_test_coverage(self) -> None:
        """æ”¶é›†æµ‹è¯•è¦†ç›–ç‡æ•°æ®"""
        logger.info("æ”¶é›†æµ‹è¯•è¦†ç›–ç‡æ•°æ®...")

        returncode, stdout, stderr = self.run_command([
            "uv", "run", "pytest",
            "--cov=src/ontology_framework",
            "--cov-report=json",
            "--cov-report=term"
        ])

        if returncode == 0:
            try:
                coverage_data = json.loads(stdout)
                totals = coverage_data.get("totals", {})

                # è®°å½•æ€»è¦†ç›–ç‡
                self.record_metric(
                    "test_coverage",
                    "total_coverage",
                    totals.get("percent_covered", 0),
                    {"covered_lines": totals.get("covered_lines", 0),
                     "num_statements": totals.get("num_statements", 0)}
                )

                # è®°å½•å„æ¨¡å—è¦†ç›–ç‡
                files = coverage_data.get("files", {})
                for file_path, file_data in files.items():
                    module_name = Path(file_path).stem
                    self.record_metric(
                        "test_coverage",
                        f"module_{module_name}",
                        file_data.get("summary", {}).get("percent_covered", 0)
                    )

            except json.JSONDecodeError as e:
                logger.error(f"è§£æè¦†ç›–ç‡æ•°æ®å¤±è´¥: {e}")
        else:
            logger.error(f"è¿è¡Œæµ‹è¯•è¦†ç›–ç‡å¤±è´¥: {stderr}")

    def collect_code_complexity(self) -> None:
        """æ”¶é›†ä»£ç å¤æ‚åº¦æ•°æ®"""
        logger.info("æ”¶é›†ä»£ç å¤æ‚åº¦æ•°æ®...")

        # å°è¯•ä½¿ç”¨radonæ”¶é›†å¤æ‚åº¦æŒ‡æ ‡
        try:
            returncode, stdout, stderr = self.run_command([
                "radon", "cc", "src", "--json"
            ])

            if returncode == 0:
                complexity_data = json.loads(stdout)

                total_complexity = 0
                max_complexity = 0
                file_count = len(complexity_data)

                for file_path, file_data in complexity_data.items():
                    for item in file_data:
                        complexity = item.get("complexity", 0)
                        total_complexity += complexity
                        max_complexity = max(max_complexity, complexity)

                avg_complexity = total_complexity / max(file_count, 1)

                self.record_metric(
                    "code_complexity",
                    "average_complexity",
                    avg_complexity,
                    {"max_complexity": max_complexity,
                     "total_files": file_count}
                )

                self.record_metric(
                    "code_complexity",
                    "max_complexity",
                    max_complexity
                )

        except (subprocess.CalledProcessError, json.JSONDecodeError, FileNotFoundError):
            logger.warning("radonä¸å¯ç”¨ï¼Œè·³è¿‡å¤æ‚åº¦åˆ†æ")

    def collect_security_metrics(self) -> None:
        """æ”¶é›†å®‰å…¨ç›¸å…³æŒ‡æ ‡"""
        logger.info("æ”¶é›†å®‰å…¨æŒ‡æ ‡...")

        # ä½¿ç”¨banditè¿›è¡Œå®‰å…¨æ‰«æ
        returncode, stdout, stderr = self.run_command([
            "bandit", "-r", "src", "-f", "json"
        ])

        if returncode in [0, 1]:  # banditè¿”å›1è¡¨ç¤ºå‘ç°é—®é¢˜ä½†æ‰«ææˆåŠŸ
            try:
                security_data = json.loads(stdout)
                results = security_data.get("results", [])

                high_issues = len([r for r in results if r.get("issue_severity") == "HIGH"])
                medium_issues = len([r for r in results if r.get("issue_severity") == "MEDIUM"])
                low_issues = len([r for r in results if r.get("issue_severity") == "LOW"])

                self.record_metric("security", "high_risk_issues", high_issues)
                self.record_metric("security", "medium_risk_issues", medium_issues)
                self.record_metric("security", "low_risk_issues", low_issues)
                self.record_metric("security", "total_issues", len(results))

            except json.JSONDecodeError:
                logger.error("è§£æå®‰å…¨æ‰«æç»“æœå¤±è´¥")

    def collect_performance_metrics(self) -> None:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        logger.info("æ”¶é›†æ€§èƒ½æŒ‡æ ‡...")

        # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
        returncode, stdout, stderr = self.run_command([
            "uv", "run", "pytest",
            "--benchmark-only",
            "--benchmark-json=/tmp/benchmark.json"
        ])

        if returncode == 0:
            try:
                with open("/tmp/benchmark.json", "r") as f:
                    benchmark_data = json.load(f)

                benchmarks = benchmark_data.get("benchmarks", [])

                for benchmark in benchmarks:
                    name = benchmark.get("name", "unknown")
                    min_time = benchmark.get("stats", {}).get("min", 0)
                    mean_time = benchmark.get("stats", {}).get("mean", 0)

                    self.record_metric(
                        "performance",
                        f"benchmark_{name}_min",
                        min_time,
                        {"benchmark_name": name}
                    )
                    self.record_metric(
                        "performance",
                        f"benchmark_{name}_mean",
                        mean_time,
                        {"benchmark_name": name}
                    )

            except (json.JSONDecodeError, FileNotFoundError):
                logger.error("è§£ææ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœå¤±è´¥")

    def collect_code_quality_metrics(self) -> None:
        """æ”¶é›†ä»£ç è´¨é‡æŒ‡æ ‡"""
        logger.info("æ”¶é›†ä»£ç è´¨é‡æŒ‡æ ‡...")

        # ç»Ÿè®¡ä»£ç è¡Œæ•°
        try:
            returncode, stdout, stderr = self.run_command([
                "find", "src", "-name", "*.py", "-exec", "wc", "-l", "{}", "+"
            ])

            if returncode == 0:
                lines = stdout.strip().split('\n')
                total_lines = sum(int(line.split()[0]) for line in lines if line.strip())

                self.record_metric(
                    "code_volume",
                    "total_lines",
                    total_lines
                )

        except Exception:
            logger.warning("ç»Ÿè®¡ä»£ç è¡Œæ•°å¤±è´¥")

        # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
        try:
            returncode, stdout, stderr = self.run_command([
                "find", "src", "-name", "*.py"
            ])

            if returncode == 0:
                file_count = len([line for line in stdout.strip().split('\n') if line.strip()])
                self.record_metric(
                    "code_volume",
                    "python_files",
                    file_count
                )

        except Exception:
            logger.warning("ç»Ÿè®¡æ–‡ä»¶æ•°é‡å¤±è´¥")

    def generate_trend_report(
        self,
        days: int = 30,
        output_file: str = "quality_trend_report.md"
    ) -> None:
        """ç”Ÿæˆè´¨é‡è¶‹åŠ¿æŠ¥å‘Š"""
        logger.info(f"ç”Ÿæˆè´¨é‡è¶‹åŠ¿æŠ¥å‘Š ({days} å¤©)...")

        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        since_date = (datetime.now() - timedelta(days=days)).isoformat()

        # è·å–å…³é”®æŒ‡æ ‡çš„è¶‹åŠ¿æ•°æ®
        key_metrics = [
            ("test_coverage", "total_coverage"),
            ("code_complexity", "average_complexity"),
            ("security", "high_risk_issues"),
            ("security", "medium_risk_issues")
        ]

        report_lines = [
            "# è´¨é‡è¶‹åŠ¿æŠ¥å‘Š",
            "",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"ç»Ÿè®¡å‘¨æœŸ: {days} å¤©",
            "",
            "## å…³é”®æŒ‡æ ‡è¶‹åŠ¿",
            ""
        ]

        for category, name in key_metrics:
            cursor.execute('''
                SELECT timestamp, metric_value
                FROM quality_metrics
                WHERE metric_category = ? AND metric_name = ? AND timestamp > ?
                ORDER BY timestamp
            ''', (category, name, since_date))

            data = cursor.fetchall()

            if data:
                report_lines.append(f"### {category}.{name}")
                latest_value = data[-1][1] if data else 0

                if data:
                    # è®¡ç®—è¶‹åŠ¿
                    values = [row[1] for row in data]
                    if len(values) >= 2:
                        trend = ((values[-1] - values[0]) / values[0]) * 100 if values[0] != 0 else 0
                        trend_symbol = "ğŸ“ˆ" if trend > 0 else "ğŸ“‰" if trend < 0 else "â¡ï¸"
                        report_lines.append(f"- å½“å‰å€¼: {latest_value:.2f}")
                        report_lines.append(f"- è¶‹åŠ¿: {trend_symbol} {trend:+.1f}%")
                    else:
                        report_lines.append(f"- å½“å‰å€¼: {latest_value:.2f}")
                        report_lines.append("- è¶‹åŠ¿: æ•°æ®ä¸è¶³")
                else:
                    report_lines.append("- æ•°æ®ä¸è¶³")

                report_lines.append("")

        # æ·»åŠ æœ€æ–°è´¨é‡æ£€æŸ¥æ‘˜è¦
        cursor.execute('''
            SELECT metric_category, metric_name, metric_value, timestamp
            FROM quality_metrics
            WHERE timestamp > datetime('now', '-1 day')
            ORDER BY timestamp DESC
            LIMIT 20
        ''')

        recent_metrics = cursor.fetchall()

        if recent_metrics:
            report_lines.extend([
                "## æœ€æ–°è´¨é‡æŒ‡æ ‡",
                "",
                "| ç±»åˆ« | æŒ‡æ ‡ | å€¼ | æ—¶é—´ |",
                "|------|------|----|----|"
            ])

            for category, name, value, timestamp in recent_metrics:
                formatted_time = timestamp.split('T')[1][:5] if 'T' in timestamp else "N/A"
                report_lines.append(f"| {category} | {name} | {value:.2f} | {formatted_time} |")

        report_content = "\n".join(report_lines)

        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        report_path = self.project_root / output_file
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        logger.info(f"è´¨é‡è¶‹åŠ¿æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")

        conn.close()

    def get_health_score(self) -> Dict[str, Any]:
        """è®¡ç®—é¡¹ç›®è´¨é‡å¥åº·è¯„åˆ†"""
        conn = sqlite3.connect(str(self.db_path))
        cursor = conn.cursor()

        # è·å–æœ€æ–°çš„å…³é”®æŒ‡æ ‡
        cursor.execute('''
            SELECT metric_category, metric_name, metric_value
            FROM quality_metrics
            WHERE (metric_category, metric_name) IN (
                ('test_coverage', 'total_coverage'),
                ('code_complexity', 'average_complexity'),
                ('security', 'high_risk_issues')
            )
            ORDER BY timestamp DESC
            LIMIT 20
        ''')

        latest_metrics = {}
        for category, name, value in cursor.fetchall():
            latest_metrics[f"{category}.{name}"] = value

        conn.close()

        # è®¡ç®—å¥åº·è¯„åˆ†
        scores = {}

        # æµ‹è¯•è¦†ç›–ç‡è¯„åˆ† (90% = æ»¡åˆ†)
        coverage = latest_metrics.get("test_coverage.total_coverage", 0)
        scores["coverage"] = min(coverage / 90, 1.0)

        # ä»£ç å¤æ‚åº¦è¯„åˆ† (5 = æ»¡åˆ†)
        complexity = latest_metrics.get("code_complexity.average_complexity", 10)
        scores["complexity"] = max(0, 1 - (complexity - 5) / 10)

        # å®‰å…¨æ€§è¯„åˆ† (0é—®é¢˜ = æ»¡åˆ†)
        security_issues = latest_metrics.get("security.high_risk_issues", 5)
        scores["security"] = max(0, 1 - security_issues / 10)

        # è®¡ç®—åŠ æƒæ€»åˆ†
        weights = {
            "coverage": 0.4,
            "complexity": 0.3,
            "security": 0.3
        }

        total_score = sum(
            scores[category] * weights[category]
            for category in scores
        )

        return {
            "total_score": total_score,
            "category_scores": scores,
            "health_level": self._get_health_level(total_score),
            "latest_metrics": latest_metrics
        }

    def _get_health_level(self, score: float) -> str:
        """è·å–å¥åº·ç­‰çº§"""
        if score >= 0.9:
            return "ä¼˜ç§€ (A)"
        elif score >= 0.8:
            return "è‰¯å¥½ (B)"
        elif score >= 0.7:
            return "åˆæ ¼ (C)"
        elif score >= 0.6:
            return "éœ€æ”¹è¿› (D)"
        else:
            return "ä¸åˆæ ¼ (F)"

    def run_full_collection(self) -> None:
        """è¿è¡Œå®Œæ•´çš„è´¨é‡æŒ‡æ ‡æ”¶é›†"""
        logger.info("å¼€å§‹æ”¶é›†è´¨é‡æŒ‡æ ‡...")

        try:
            self.collect_test_coverage()
            self.collect_code_complexity()
            self.collect_security_metrics()
            self.collect_performance_metrics()
            self.collect_code_quality_metrics()

            logger.info("è´¨é‡æŒ‡æ ‡æ”¶é›†å®Œæˆ")

            # ç”Ÿæˆå¥åº·è¯„åˆ†
            health_score = self.get_health_score()
            logger.info(f"é¡¹ç›®å¥åº·è¯„åˆ†: {health_score['total_score']:.2f} ({health_score['health_level']})")

        except Exception as e:
            logger.error(f"è´¨é‡æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
            raise


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è´¨é‡ç›‘æ§è„šæœ¬")
    parser.add_argument(
        "--project-root",
        default=".",
        help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--collect",
        action="store_true",
        help="æ”¶é›†è´¨é‡æŒ‡æ ‡"
    )
    parser.add_argument(
        "--report",
        action="store_true",
        help="ç”Ÿæˆè´¨é‡è¶‹åŠ¿æŠ¥å‘Š"
    )
    parser.add_argument(
        "--days",
        type=int,
        default=30,
        help="æŠ¥å‘Šç»Ÿè®¡å¤©æ•°"
    )
    parser.add_argument(
        "--output",
        default="quality_trend_report.md",
        help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶å"
    )
    parser.add_argument(
        "--health",
        action="store_true",
        help="æ˜¾ç¤ºé¡¹ç›®å¥åº·è¯„åˆ†"
    )

    args = parser.parse_args()

    collector = QualityMetricsCollector(args.project_root)

    if args.collect:
        collector.run_full_collection()

    if args.report:
        collector.generate_trend_report(args.days, args.output)

    if args.health:
        health_score = collector.get_health_score()
        print(f"é¡¹ç›®å¥åº·è¯„åˆ†: {health_score['total_score']:.2f} ({health_score['health_level']})")
        print("\nå„ç»´åº¦è¯„åˆ†:")
        for category, score in health_score['category_scores'].items():
            print(f"  {category}: {score:.2f}")

    if not any([args.collect, args.report, args.health]):
        # é»˜è®¤è¡Œä¸ºï¼šæ”¶é›†æŒ‡æ ‡å¹¶ç”ŸæˆæŠ¥å‘Š
        collector.run_full_collection()
        collector.generate_trend_report()


if __name__ == "__main__":
    main()